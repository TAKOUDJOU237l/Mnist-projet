#  Classification de Chiffres MNIST avec Deep Learning et MLflow

##  Description du projet

Ce projet impl√©mente un r√©seau de neurones profond (Deep Neural Network) pour la classification de chiffres manuscrits en utilisant le dataset MNIST. Le projet int√®gre **MLflow** pour le tracking complet des exp√©rimentations, permettant une gestion professionnelle du cycle de vie du mod√®le de Machine Learning.

## Objectifs

- Construire un mod√®le de classification performant pour reconna√Ætre les chiffres de 0 √† 9
- Impl√©menter le tracking des exp√©riences avec MLflow
- G√©rer le versioning des mod√®les et des hyperparam√®tres
- Faciliter la reproductibilit√© et la comparaison des exp√©rimentations

##  Dataset : MNIST

Le dataset MNIST (Modified National Institute of Standards and Technology) est une r√©f√©rence en Deep Learning :

- **60 000 images** d'entra√Ænement
- **10 000 images** de test
- Images en **niveaux de gris** de **28√ó28 pixels**
- **10 classes** (chiffres de 0 √† 9)
- Dataset pr√©charg√© via `keras.datasets.mnist`

## Architecture du Mod√®le

### Structure du r√©seau

Le mod√®le utilise une architecture de r√©seau de neurones enti√®rement connect√© (Fully Connected Network) :

```
Input (784) ‚Üí Dense (512, ReLU) ‚Üí Dropout (0.2) ‚Üí Dense (10, Softmax)
```

**D√©tails des couches :**

1. **Couche d'entr√©e** : 784 neurones (28√ó28 pixels aplatis)
2. **Couche cach√©e Dense** : 512 neurones avec activation ReLU
3. **Couche Dropout** : 20% de dropout pour la r√©gularisation
4. **Couche de sortie** : 10 neurones avec activation Softmax (probabilit√©s par classe)

**Nombre total de param√®tres entra√Ænables** : ~407 050 param√®tres

### Choix techniques

- **Activation ReLU** : Fonction d'activation non-lin√©aire efficace pour les couches cach√©es
- **Dropout** : Pr√©vient le surapprentissage en d√©sactivant al√©atoirement des neurones
- **Softmax** : Transforme les sorties en distribution de probabilit√© pour la classification multi-classes
- **Optimiseur Adam** : Convergence rapide avec adaptation automatique du learning rate

## ‚öôÔ∏è Hyperparam√®tres

| Hyperparam√®tre | Valeur | Description |
|----------------|--------|-------------|
| **Epochs** | 5 | Nombre de passages complets sur le dataset |
| **Batch Size** | 128 | Nombre d'exemples par batch |
| **Validation Split** | 0.1 (10%) | Proportion des donn√©es d'entra√Ænement pour la validation |
| **Hidden Units** | 512 | Nombre de neurones dans la couche cach√©e |
| **Dropout Rate** | 0.2 (20%) | Taux de dropout pour la r√©gularisation |
| **Optimizer** | Adam | Algorithme d'optimisation |
| **Loss Function** | Sparse Categorical Crossentropy | Fonction de perte pour classification |

##  Installation et Configuration

### Pr√©requis

- Python 3.8+
- pip

### Installation des d√©pendances

```bash
pip install tensorflow numpy mlflow
```

Ou avec un fichier `requirements.txt` :

```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```
tensorflow==2.15.0
numpy==1.24.3
mlflow==2.8.0
```

## Structure du Projet

```
MNIST_MLflow_Project/
‚îú‚îÄ‚îÄ train_model.py          # Script principal d'entra√Ænement
‚îú‚îÄ‚îÄ mnist_model.h5          # Mod√®le entra√Æn√© (g√©n√©r√©)
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îú‚îÄ‚îÄ README.md               # Documentation
‚îî‚îÄ‚îÄ mlruns/                 # Dossier MLflow (g√©n√©r√© automatiquement)
    ‚îî‚îÄ‚îÄ 0/
        ‚îî‚îÄ‚îÄ [run_id]/
            ‚îú‚îÄ‚îÄ artifacts/  # Mod√®les et fichiers sauvegard√©s
            ‚îú‚îÄ‚îÄ metrics/    # M√©triques enregistr√©es
            ‚îú‚îÄ‚îÄ params/     # Hyperparam√®tres
            ‚îî‚îÄ‚îÄ tags/       # Tags et m√©tadonn√©es
```

## Utilisation

### 1. Entra√Æner le mod√®le

Lancez le script d'entra√Ænement :

```bash
python train_model.py
```

**Ce que fait le script :**
1.  Charge automatiquement le dataset MNIST
2.  Pr√©traite les donn√©es (normalisation et redimensionnement)
3.  Construit le mod√®le de r√©seau de neurones
4.  Entra√Æne le mod√®le sur 5 √©poques
5.  √âvalue les performances sur le jeu de test
6.  Enregistre toutes les m√©triques et param√®tres dans MLflow
7.  Sauvegarde le mod√®le au format `.h5` et dans le Model Registry MLflow

### 2. Visualiser les r√©sultats avec MLflow UI

Apr√®s l'entra√Ænement, lancez l'interface web MLflow :

```bash
mlflow ui
```

Puis ouvrez votre navigateur √† l'adresse : **http://localhost:5000**

### 3. Explorer l'interface MLflow

Dans MLflow UI, vous pouvez :

-  **Comparer diff√©rentes ex√©cutions** (runs) c√¥te √† c√¥te
-  **Visualiser l'√©volution des m√©triques** (accuracy, loss) par √©poque
-  **Filtrer et trier** les exp√©riences par performances
-  **T√©l√©charger les mod√®les** sauvegard√©s
-  **G√©rer les versions** dans le Model Registry

##  M√©triques Track√©es

### Hyperparam√®tres enregistr√©s
- Nombre d'√©poques, batch size, validation split
- Architecture du r√©seau (hidden units, dropout rate)
- Optimiseur et fonctions d'activation
- Informations sur le dataset (nombre d'√©chantillons, classes)

### M√©triques d'entra√Ænement (par √©poque)
- `train_loss` : Perte sur les donn√©es d'entra√Ænement
- `train_accuracy` : Pr√©cision sur les donn√©es d'entra√Ænement
- `val_loss` : Perte sur les donn√©es de validation
- `val_accuracy` : Pr√©cision sur les donn√©es de validation

### M√©triques finales
- `test_loss` : Perte sur le jeu de test
- `test_accuracy` : Pr√©cision finale sur le jeu de test

## R√©sultats Attendus

Le mod√®le atteint g√©n√©ralement une **pr√©cision de ~97-98%** sur le jeu de test apr√®s 5 √©poques d'entra√Ænement.

**Exemple de sortie :**
```
Pr√©cision sur les donn√©es de test : 0.9785
Perte sur les donn√©es de test : 0.0721
```

##  Workflow du Projet

```
1. Chargement des donn√©es MNIST
         ‚Üì
2. Pr√©traitement (normalisation + reshape)
         ‚Üì
3. Construction du mod√®le
         ‚Üì
4. Compilation avec Adam optimizer
         ‚Üì
5. Entra√Ænement avec tracking MLflow
         ‚Üì
6. √âvaluation sur le jeu de test
         ‚Üì
7. Sauvegarde du mod√®le et logging dans MLflow
         ‚Üì
8. Visualisation des r√©sultats via MLflow UI
```

## üîß Concepts Cl√©s Impl√©ment√©s

### 1. Deep Learning
- **R√©seaux de neurones multicouches** (Dense layers)
- **Fonctions d'activation** (ReLU, Softmax)
- **R√©gularisation** (Dropout)
- **Optimisation stochastique** (Adam optimizer)
- **Backpropagation** pour la mise √† jour des poids

### 2. MLflow Tracking
- **Experiment tracking** : Organisation des runs par exp√©rience
- **Parameter logging** : Enregistrement automatique des hyperparam√®tres
- **Metric logging** : Suivi des performances par √©poque
- **Model registry** : Versioning et gestion des mod√®les
- **Artifact storage** : Sauvegarde des mod√®les et fichiers

### 3. Bonnes Pratiques ML
- **S√©paration train/validation/test** pour √©valuation robuste
- **Normalisation des donn√©es** pour acc√©l√©rer la convergence
- **Vectorisation** des op√©rations pour optimiser les calculs
- **Batch processing** pour g√©rer efficacement la m√©moire

## Am√©liorations Possibles

### Architecture
- [ ] Ajouter des couches cach√©es suppl√©mentaires
- [ ] Exp√©rimenter avec des CNN (Convolutional Neural Networks)
- [ ] Tester diff√©rentes fonctions d'activation (LeakyReLU, ELU)
- [ ] Impl√©menter Batch Normalization

### Entra√Ænement
- [ ] Augmenter le nombre d'√©poques (10-20)
- [ ] Impl√©menter Early Stopping pour √©viter le surapprentissage
- [ ] Ajouter des callbacks (ModelCheckpoint, ReduceLROnPlateau)
- [ ] Exp√©rimenter avec Learning Rate Scheduling

### Optimisation
- [ ] Hyperparameter tuning avec Optuna ou Hyperopt
- [ ] Grid Search ou Random Search sur les hyperparam√®tres
- [ ] Utiliser des techniques d'augmentation de donn√©es

### D√©ploiement
- [ ] Cr√©er une API REST avec Flask/FastAPI
- [ ] Conteneurisation avec Docker
- [ ] D√©ploiement sur Cloud (GCP, AWS, Azure)
- [ ] Mise en place d'un pipeline CI/CD

## üìä Utilisation Avanc√©e de MLflow

### Comparer plusieurs runs

```python
# Lancer plusieurs exp√©rimentations avec diff√©rents hyperparam√®tres
hidden_units_options = [128, 256, 512, 1024]
dropout_rates = [0.1, 0.2, 0.3, 0.5]

for hidden in hidden_units_options:
    for dropout in dropout_rates:
        with mlflow.start_run():
            # Entra√Æner avec ces param√®tres
            mlflow.log_param("hidden_units", hidden)
            mlflow.log_param("dropout_rate", dropout)
            # ... reste du code
```

### Charger un mod√®le depuis MLflow

```python
import mlflow.keras

# Charger le meilleur mod√®le
model_uri = "models:/MNIST_DNN_Model/Production"
loaded_model = mlflow.keras.load_model(model_uri)

# Faire des pr√©dictions
predictions = loaded_model.predict(x_test[:10])
```

### Filtrer les runs dans l'API MLflow

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()
experiment = client.get_experiment_by_name("MNIST_Classification")

# R√©cup√©rer les meilleurs runs
runs = client.search_runs(
    experiment_ids=[experiment.experiment_id],
    filter_string="metrics.test_accuracy > 0.97",
    order_by=["metrics.test_accuracy DESC"]
)
```

##  D√©bogage et Troubleshooting

### Probl√®me : "No module named 'mlflow'"
```bash
pip install mlflow
```

### Probl√®me : Port 5000 d√©j√† utilis√©
```bash
mlflow ui --port 5001
```

### Probl√®me : Mod√®le non trouv√©
Assurez-vous que le fichier `mnist_model.h5` existe dans le r√©pertoire courant.

### Probl√®me : Performances faibles
- V√©rifiez la normalisation des donn√©es
- Augmentez le nombre d'√©poques
- Essayez diff√©rents learning rates

##  Ressources et R√©f√©rences

- [Documentation TensorFlow/Keras](https://www.tensorflow.org/guide/keras)
- [Documentation MLflow](https://mlflow.org/docs/latest/index.html)
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [Adam Optimizer Paper](https://arxiv.org/abs/1412.6980)

##  Auteur

Projet r√©alis√© dans le cadre d'un TP sur les r√©seaux de neurones et le Deep Learning.

**Sujet :** De la conception au d√©ploiement de mod√®les de Deep Learning

##  Licence

Ce projet est √† usage √©ducatif.

---

##  Concepts P√©dagogiques Couverts

**Fondamentaux du Deep Learning**
- Descente de gradient stochastique (SGD)
- Backpropagation
- Fonctions d'activation (ReLU, Softmax)
- R√©gularisation (Dropout)

 **Optimisation**
- Adam optimizer
- Vectorisation des calculs
- Mini-batch processing

 **MLOps et Bonnes Pratiques**
- Experiment tracking avec MLflow
- Versioning des mod√®les
- Reproductibilit√© des exp√©rimentations
- Model registry

 **√âvaluation de Mod√®les**
- S√©paration train/validation/test
- M√©triques de classification
- Monitoring des performances

---

**Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue sur GitHub !** 
